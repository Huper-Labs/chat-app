model_list:
  # OpenAI Models - GPT-4o Series
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  
  # OpenAI Models - GPT-4.1 Series (Coding-Focused)
  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: gpt-4.1-mini
    litellm_params:
      model: openai/gpt-4.1-mini
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: gpt-4.1-nano
    litellm_params:
      model: openai/gpt-4.1-nano
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  
  # OpenAI Models - o-Series (Reasoning Models)
  - model_name: o1
    litellm_params:
      model: openai/o1
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: o1-mini
    litellm_params:
      model: openai/o1-mini
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: o1-pro
    litellm_params:
      model: openai/o1-pro
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  
  # OpenAI Models - o3 Series (Latest Reasoning Models)
  - model_name: o3
    litellm_params:
      model: openai/o3
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: o3-pro
    litellm_params:
      model: openai/o3-pro
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: o3-mini
    litellm_params:
      model: openai/o3-mini
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  
  # OpenAI Models - Legacy
  - model_name: gpt-4
    litellm_params:
      model: openai/gpt-4
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: gpt-4-turbo
    litellm_params:
      model: openai/gpt-4-turbo-preview
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  
  # Anthropic Models - Claude 4 Family (Latest)
  - model_name: claude-opus-4
    litellm_params:
      model: anthropic/claude-opus-4
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: claude-sonnet-4
    litellm_params:
      model: anthropic/claude-sonnet-4
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  
  # Anthropic Models - Claude 3.5 Family
  - model_name: claude-3.5-sonnet
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: claude-3.5-haiku
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  
  # Anthropic Models - Claude 3 Family
  - model_name: claude-3-opus
    litellm_params:
      model: anthropic/claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: claude-3-sonnet
    litellm_params:
      model: anthropic/claude-3-sonnet-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: claude-3-haiku
    litellm_params:
      model: anthropic/claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  
  # Google Models - Gemini 2.5 Family (Latest)
  - model_name: gemini-2.5-pro
    litellm_params:
      model: gemini/gemini-2.5-pro
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.5-flash-lite
    litellm_params:
      model: gemini/gemini-2.5-flash-lite
      api_key: os.environ/GEMINI_API_KEY
  
  # Google Models - Gemini 2.0 Family
  - model_name: gemini-2.0-flash
    litellm_params:
      model: gemini/gemini-2.0-flash
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.0-pro-exp
    litellm_params:
      model: gemini/gemini-2.0-pro-experimental
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.0-flash-lite
    litellm_params:
      model: gemini/gemini-2.0-flash-lite
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.0-flash-live
    litellm_params:
      model: gemini/gemini-2.0-flash-live
      api_key: os.environ/GEMINI_API_KEY
  
  # Google Models - Gemini 1.5 Family
  - model_name: gemini-1.5-pro
    litellm_params:
      model: gemini/gemini-1.5-pro-latest
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-1.5-flash
    litellm_params:
      model: gemini/gemini-1.5-flash-latest
      api_key: os.environ/GEMINI_API_KEY
  
  # Google Models - Legacy
  - model_name: gemini-pro
    litellm_params:
      model: gemini/gemini-pro
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-pro-vision
    litellm_params:
      model: gemini/gemini-pro-vision
      api_key: os.environ/GEMINI_API_KEY
  
  # Cohere Models
  - model_name: command-r
    litellm_params:
      model: cohere/command-r
      api_key: os.environ/COHERE_API_KEY
  - model_name: command-r-plus
    litellm_params:
      model: cohere/command-r-plus
      api_key: os.environ/COHERE_API_KEY
  
  # Mistral Models
  - model_name: mistral-tiny
    litellm_params:
      model: mistral/mistral-tiny
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mistral-small
    litellm_params:
      model: mistral/mistral-small-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mistral-medium
    litellm_params:
      model: mistral/mistral-medium-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mistral-large
    litellm_params:
      model: mistral/mistral-large-latest
      api_key: os.environ/MISTRAL_API_KEY
  
  # Groq Models (Fast Inference)
  - model_name: mixtral-8x7b
    litellm_params:
      model: groq/mixtral-8x7b-32768
      api_key: os.environ/GROQ_API_KEY
  - model_name: llama3-70b
    litellm_params:
      model: groq/llama3-70b-8192
      api_key: os.environ/GROQ_API_KEY
  - model_name: llama3-8b
    litellm_params:
      model: groq/llama3-8b-8192
      api_key: os.environ/GROQ_API_KEY
  
  # Together AI Models
  - model_name: llama-3-70b-together
    litellm_params:
      model: together_ai/meta-llama/Llama-3-70b-chat-hf
      api_key: os.environ/TOGETHERAI_API_KEY
  - model_name: mixtral-8x22b
    litellm_params:
      model: together_ai/mistralai/Mixtral-8x22B-Instruct-v0.1
      api_key: os.environ/TOGETHERAI_API_KEY
  
  # Perplexity Models
  - model_name: perplexity-sonar-small
    litellm_params:
      model: perplexity/sonar-small-chat
      api_key: os.environ/PERPLEXITY_API_KEY
  - model_name: perplexity-sonar-medium
    litellm_params:
      model: perplexity/sonar-medium-chat
      api_key: os.environ/PERPLEXITY_API_KEY
  
  # xAI Models - Grok Series
  - model_name: grok-4
    litellm_params:
      model: xai/grok-4
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-4-latest
    litellm_params:
      model: xai/grok-4-latest
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-4-0709
    litellm_params:
      model: xai/grok-4-0709
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-3
    litellm_params:
      model: xai/grok-3
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-3-mini
    litellm_params:
      model: xai/grok-3-mini-beta
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-beta
    litellm_params:
      model: xai/grok-beta
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-2-vision-latest
    litellm_params:
      model: xai/grok-2-vision-latest
      api_key: os.environ/XAI_API_KEY
  
  # AWS Bedrock Models (if AWS credentials are configured)
  - model_name: claude-3-sonnet-bedrock
    litellm_params:
      model: bedrock/anthropic.claude-3-sonnet-20240229-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: os.environ/AWS_REGION_NAME
  
  # Azure OpenAI (example - needs configuration)
  - model_name: gpt-4-azure
    litellm_params:
      model: azure/gpt-4-deployment
      api_base: os.environ/AZURE_API_BASE
      api_key: os.environ/AZURE_API_KEY
      api_version: os.environ/AZURE_API_VERSION
  
  # Embedding Models
  - model_name: text-embedding-3-small
    litellm_params:
      model: openai/text-embedding-3-small
      api_key: os.environ/OPENAI_API_KEY
  - model_name: text-embedding-3-large
    litellm_params:
      model: openai/text-embedding-3-large
      api_key: os.environ/OPENAI_API_KEY
  - model_name: text-embedding-ada-002
    litellm_params:
      model: openai/text-embedding-ada-002
      api_key: os.environ/OPENAI_API_KEY
  - model_name: voyage-2
    litellm_params:
      model: voyage/voyage-2
      api_key: os.environ/VOYAGE_API_KEY

litellm_settings:
  drop_params: true
  set_verbose: false
  
  # Caching Configuration
  cache: true
  cache_params:
    type: redis
    host: os.environ/REDIS_HOST
    port: os.environ/REDIS_PORT
    password: os.environ/REDIS_PASSWORD
    ttl: 3600  # Cache for 1 hour
    namespace: "litellm_cache"
    
  # Success/Failure Callbacks (optional)
  # success_callback: ["langfuse", "webhook"]
  # failure_callback: ["langfuse", "webhook"]
  
  # Request Timeout
  request_timeout: 600
  
  # Retry Policy
  num_retries: 3
  retry_after: 5  # seconds

general_settings:
  # Master key for authentication
  master_key: os.environ/LITELLM_MASTER_KEY
  
  # Database Configuration
  database_url: os.environ/DATABASE_URL
  
  # Store model info in database
  store_model_in_db: true
  
  # UI Authentication
  ui_username: os.environ/UI_USERNAME
  ui_password: os.environ/UI_PASSWORD
  
  # Security
  custom_auth_header: "Authorization"
  max_parallel_requests: 100
  
  # User tracking for Open WebUI integration
  user_header_name: "X-OpenWebUI-User-Id"  # Options: X-OpenWebUI-User-Id, X-OpenWebUI-User-Email, X-OpenWebUI-User-Name
  
  # Logging
  json_logs: true
  
  # Health check endpoint
  health_check_interval: 60

router_settings:
  routing_strategy: "usage-based-routing-v2"
  
  # Model fallbacks
  model_group_alias: {
    "grok-4": ["grok-4", "grok-4-latest", "grok-3", "claude-opus-4", "o3", "gpt-4o"],
    "grok-3": ["grok-3", "grok-beta", "claude-3.5-sonnet", "gpt-4o", "gemini-2.5-flash"],
    "grok-3-mini": ["grok-3-mini", "grok-beta", "claude-3.5-haiku", "gpt-4o-mini", "gemini-2.5-flash-lite"],
    "gemini-2.5-pro": ["gemini-2.5-pro", "gemini-2.0-pro-exp", "gemini-1.5-pro", "claude-opus-4", "grok-4", "gpt-4o"],
    "gemini-2.5-flash": ["gemini-2.5-flash", "gemini-2.0-flash", "gemini-1.5-flash", "claude-3.5-sonnet", "grok-3", "gpt-4o"],
    "gemini-2.5-flash-lite": ["gemini-2.5-flash-lite", "gemini-2.0-flash-lite", "gemini-1.5-flash", "claude-3.5-haiku", "grok-3-mini", "gpt-4o-mini"],
    "claude-opus-4": ["claude-opus-4", "claude-3.5-sonnet", "claude-3-opus", "grok-4", "gemini-2.5-pro", "gpt-4o"],
    "claude-sonnet-4": ["claude-sonnet-4", "claude-3.5-sonnet", "grok-3", "gemini-2.5-flash", "gpt-4o", "claude-3-sonnet"],
    "claude-3.5-sonnet": ["claude-3.5-sonnet", "claude-3-sonnet", "grok-3", "gpt-4o", "gemini-2.5-flash", "gemini-1.5-pro"],
    "claude-3.5-haiku": ["claude-3.5-haiku", "claude-3-haiku", "grok-3-mini", "gpt-4o-mini", "gemini-2.5-flash-lite", "gemini-1.5-flash"],
    "gpt-4o": ["gpt-4o", "gpt-4.1", "grok-4", "claude-sonnet-4", "claude-3.5-sonnet", "gemini-2.5-flash", "gemini-1.5-pro"],
    "gpt-4o-mini": ["gpt-4o-mini", "gpt-4.1-mini", "grok-3-mini", "claude-3.5-haiku", "claude-3-haiku", "gemini-2.5-flash-lite", "gemini-1.5-flash"],
    "o3": ["o3", "o3-pro", "o1", "grok-4", "claude-opus-4", "gemini-2.5-pro", "gpt-4o"],
    "o3-mini": ["o3-mini", "o1-mini", "grok-3-mini", "gpt-4o-mini", "claude-3.5-haiku", "gemini-2.5-flash-lite"],
    "gpt-4": ["gpt-4", "gpt-4o", "claude-3-opus", "gemini-1.5-pro"],
    "gpt-3.5-turbo": ["gpt-3.5-turbo", "gpt-4o-mini", "claude-3-haiku", "gemini-1.5-flash"],
  }
  
  # Redis settings for load balancing
  redis_host: os.environ/REDIS_HOST
  redis_port: os.environ/REDIS_PORT
  redis_password: os.environ/REDIS_PASSWORD
  
  # Cooldown settings
  cooldown_time: 30
  allowed_fails: 3
  
  # Enable fallbacks
  enable_fallbacks: true