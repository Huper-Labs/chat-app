model_list:
  # OpenAI Models - GPT-4o Series
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  
  # OpenAI Models - GPT-4.1 Series (Coding-Focused)
  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: gpt-4.1-mini
    litellm_params:
      model: openai/gpt-4.1-mini
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: gpt-4.1-nano
    litellm_params:
      model: openai/gpt-4.1-nano
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  
  # OpenAI Models - o-Series (Reasoning Models)
  - model_name: o1
    litellm_params:
      model: openai/o1
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: o1-mini
    litellm_params:
      model: openai/o1-mini
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: o1-pro
    litellm_params:
      model: openai/o1-pro
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  
  # OpenAI Models - o3 Series (Latest Reasoning Models)
  - model_name: o3
    litellm_params:
      model: openai/o3
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: o3-pro
    litellm_params:
      model: openai/o3-pro
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: o3-mini
    litellm_params:
      model: openai/o3-mini
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  
  # OpenAI Models - Legacy
  - model_name: gpt-4
    litellm_params:
      model: openai/gpt-4
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: gpt-4-turbo
    litellm_params:
      model: openai/gpt-4-turbo-preview
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
      merge_reasoning_content_in_choices: true
  
  # Anthropic Models - Claude 4 Family (Latest)
  - model_name: claude-opus-4
    litellm_params:
      model: anthropic/claude-opus-4
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: claude-sonnet-4
    litellm_params:
      model: anthropic/claude-sonnet-4
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  
  # Anthropic Models - Claude 3.5 Family
  - model_name: claude-3.5-sonnet
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: claude-3.5-haiku
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  
  # Anthropic Models - Claude 3 Family
  - model_name: claude-3-opus
    litellm_params:
      model: anthropic/claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: claude-3-sonnet
    litellm_params:
      model: anthropic/claude-3-sonnet-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  - model_name: claude-3-haiku
    litellm_params:
      model: anthropic/claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
      merge_reasoning_content_in_choices: true
  
  # Google Models - Gemini 2.5 Family (Latest)
  - model_name: gemini-2.5-pro
    litellm_params:
      model: gemini/gemini-2.5-pro
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.5-flash-lite
    litellm_params:
      model: gemini/gemini-2.5-flash-lite
      api_key: os.environ/GEMINI_API_KEY
  
  # Google Models - Gemini 2.0 Family
  - model_name: gemini-2.0-flash
    litellm_params:
      model: gemini/gemini-2.0-flash
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.0-pro-exp
    litellm_params:
      model: gemini/gemini-2.0-pro-experimental
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.0-flash-lite
    litellm_params:
      model: gemini/gemini-2.0-flash-lite
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.0-flash-live
    litellm_params:
      model: gemini/gemini-2.0-flash-live
      api_key: os.environ/GEMINI_API_KEY
  
  # Google Models - Gemini 1.5 Family
  - model_name: gemini-1.5-pro
    litellm_params:
      model: gemini/gemini-1.5-pro-latest
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-1.5-flash
    litellm_params:
      model: gemini/gemini-1.5-flash-latest
      api_key: os.environ/GEMINI_API_KEY
  
  # Google Models - Legacy
  - model_name: gemini-pro
    litellm_params:
      model: gemini/gemini-pro
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-pro-vision
    litellm_params:
      model: gemini/gemini-pro-vision
      api_key: os.environ/GEMINI_API_KEY
  
  # Cohere Models - Command Family
  - model_name: command-a
    litellm_params:
      model: cohere/command-a-03-2025
      api_key: os.environ/COHERE_API_KEY
  - model_name: command-r-plus-08-2024
    litellm_params:
      model: cohere/command-r-plus-08-2024
      api_key: os.environ/COHERE_API_KEY
  - model_name: command-r-08-2024
    litellm_params:
      model: cohere/command-r-08-2024
      api_key: os.environ/COHERE_API_KEY
  - model_name: command-r-plus
    litellm_params:
      model: cohere/command-r-plus
      api_key: os.environ/COHERE_API_KEY
  - model_name: command-r
    litellm_params:
      model: cohere/command-r
      api_key: os.environ/COHERE_API_KEY
  - model_name: command-nightly
    litellm_params:
      model: cohere/command-nightly
      api_key: os.environ/COHERE_API_KEY
  
  # Mistral Models - Latest
  - model_name: pixtral-large
    litellm_params:
      model: mistral/pixtral-large-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mistral-large
    litellm_params:
      model: mistral/mistral-large-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mistral-medium
    litellm_params:
      model: mistral/mistral-medium-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mistral-small
    litellm_params:
      model: mistral/mistral-small-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mistral-saba
    litellm_params:
      model: mistral/mistral-saba-latest
      api_key: os.environ/MISTRAL_API_KEY
  
  # Mistral Models - Reasoning
  - model_name: magistral-medium
    litellm_params:
      model: mistral/magistral-medium
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: magistral-small
    litellm_params:
      model: mistral/magistral-small
      api_key: os.environ/MISTRAL_API_KEY
  
  # Mistral Models - Edge
  - model_name: ministral-8b
    litellm_params:
      model: mistral/ministral-8b-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: ministral-3b
    litellm_params:
      model: mistral/ministral-3b-latest
      api_key: os.environ/MISTRAL_API_KEY
  
  # Mistral Models - Coding
  - model_name: codestral
    litellm_params:
      model: mistral/codestral-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: devstral-medium
    litellm_params:
      model: mistral/devstral-medium-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: devstral-small
    litellm_params:
      model: mistral/devstral-small-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: codestral-mamba
    litellm_params:
      model: mistral/codestral-mamba-latest
      api_key: os.environ/MISTRAL_API_KEY
  
  # Mistral Models - Multimodal
  - model_name: pixtral-12b
    litellm_params:
      model: mistral/pixtral-12b-2409
      api_key: os.environ/MISTRAL_API_KEY
  
  # Mistral Models - Voice
  - model_name: voxtral-small
    litellm_params:
      model: mistral/voxtral-small-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: voxtral-mini
    litellm_params:
      model: mistral/voxtral-mini-latest
      api_key: os.environ/MISTRAL_API_KEY
  
  # Mistral Models - Specialized
  - model_name: mistral-ocr
    litellm_params:
      model: mistral/mistral-ocr-latest
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mathstral-7b
    litellm_params:
      model: mistral/mathstral-7b-v0.1
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mistral-moderation
    litellm_params:
      model: mistral/mistral-moderation-latest
      api_key: os.environ/MISTRAL_API_KEY
  
  # Mistral Models - Open Source
  - model_name: mistral-nemo
    litellm_params:
      model: mistral/open-mistral-nemo
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mistral-7b
    litellm_params:
      model: mistral/open-mistral-7b
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mixtral-8x7b
    litellm_params:
      model: mistral/open-mixtral-8x7b
      api_key: os.environ/MISTRAL_API_KEY
  - model_name: mixtral-8x22b
    litellm_params:
      model: mistral/open-mixtral-8x22b
      api_key: os.environ/MISTRAL_API_KEY
  
  # Mistral Models - Legacy
  - model_name: mistral-tiny
    litellm_params:
      model: mistral/mistral-tiny
      api_key: os.environ/MISTRAL_API_KEY
  
  # Groq Models (Fast Inference)
  - model_name: groq-mixtral-8x7b
    litellm_params:
      model: groq/mixtral-8x7b-32768
      api_key: os.environ/GROQ_API_KEY
  - model_name: llama3-70b
    litellm_params:
      model: groq/llama3-70b-8192
      api_key: os.environ/GROQ_API_KEY
  - model_name: llama3-8b
    litellm_params:
      model: groq/llama3-8b-8192
      api_key: os.environ/GROQ_API_KEY
  
  # Together AI Models
  - model_name: llama-3-70b-together
    litellm_params:
      model: together_ai/meta-llama/Llama-3-70b-chat-hf
      api_key: os.environ/TOGETHERAI_API_KEY
  - model_name: mixtral-8x22b
    litellm_params:
      model: together_ai/mistralai/Mixtral-8x22B-Instruct-v0.1
      api_key: os.environ/TOGETHERAI_API_KEY
  
  # Perplexity Models - Sonar Family
  - model_name: sonar-pro
    litellm_params:
      model: perplexity/sonar-pro
      api_key: os.environ/PERPLEXITY_API_KEY
  - model_name: sonar
    litellm_params:
      model: perplexity/sonar
      api_key: os.environ/PERPLEXITY_API_KEY
  
  # Perplexity Models - Reasoning
  - model_name: sonar-reasoning-pro
    litellm_params:
      model: perplexity/sonar-reasoning-pro
      api_key: os.environ/PERPLEXITY_API_KEY
  - model_name: sonar-reasoning
    litellm_params:
      model: perplexity/sonar-reasoning
      api_key: os.environ/PERPLEXITY_API_KEY
  - model_name: r1-1776
    litellm_params:
      model: perplexity/r1-1776
      api_key: os.environ/PERPLEXITY_API_KEY
  
  # Perplexity Models - Research
  - model_name: sonar-deep-research
    litellm_params:
      model: perplexity/sonar-deep-research
      api_key: os.environ/PERPLEXITY_API_KEY
  
  # Perplexity Models - Legacy/Chat
  - model_name: llama-3.1-sonar-small-128k-online
    litellm_params:
      model: perplexity/llama-3.1-sonar-small-128k-online
      api_key: os.environ/PERPLEXITY_API_KEY
  - model_name: llama-3.1-sonar-large-128k-online
    litellm_params:
      model: perplexity/llama-3.1-sonar-large-128k-online
      api_key: os.environ/PERPLEXITY_API_KEY
  - model_name: llama-3.1-sonar-small-128k-chat
    litellm_params:
      model: perplexity/llama-3.1-sonar-small-128k-chat
      api_key: os.environ/PERPLEXITY_API_KEY
  - model_name: llama-3.1-sonar-large-128k-chat
    litellm_params:
      model: perplexity/llama-3.1-sonar-large-128k-chat
      api_key: os.environ/PERPLEXITY_API_KEY
  
  # xAI Models - Grok Series
  - model_name: grok-4
    litellm_params:
      model: xai/grok-4
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-4-latest
    litellm_params:
      model: xai/grok-4-latest
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-4-0709
    litellm_params:
      model: xai/grok-4-0709
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-3
    litellm_params:
      model: xai/grok-3
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-3-mini
    litellm_params:
      model: xai/grok-3-mini-beta
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-beta
    litellm_params:
      model: xai/grok-beta
      api_key: os.environ/XAI_API_KEY
  - model_name: grok-2-vision-latest
    litellm_params:
      model: xai/grok-2-vision-latest
      api_key: os.environ/XAI_API_KEY
  
  # AWS Bedrock Models (if AWS credentials are configured)
  - model_name: claude-3-sonnet-bedrock
    litellm_params:
      model: bedrock/anthropic.claude-3-sonnet-20240229-v1:0
      aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
      aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
      aws_region_name: os.environ/AWS_REGION_NAME
  
  # Azure OpenAI (example - needs configuration)
  - model_name: gpt-4-azure
    litellm_params:
      model: azure/gpt-4-deployment
      api_base: os.environ/AZURE_API_BASE
      api_key: os.environ/AZURE_API_KEY
      api_version: os.environ/AZURE_API_VERSION
  
  # Embedding Models - OpenAI
  - model_name: text-embedding-3-small
    litellm_params:
      model: openai/text-embedding-3-small
      api_key: os.environ/OPENAI_API_KEY
  - model_name: text-embedding-3-large
    litellm_params:
      model: openai/text-embedding-3-large
      api_key: os.environ/OPENAI_API_KEY
  - model_name: text-embedding-ada-002
    litellm_params:
      model: openai/text-embedding-ada-002
      api_key: os.environ/OPENAI_API_KEY
  
  # Embedding Models - Cohere
  - model_name: embed-english-v3.0
    litellm_params:
      model: cohere/embed-english-v3.0
      api_key: os.environ/COHERE_API_KEY
      input_type: search_document
  - model_name: embed-english-light-v3.0
    litellm_params:
      model: cohere/embed-english-light-v3.0
      api_key: os.environ/COHERE_API_KEY
      input_type: search_document
  - model_name: embed-multilingual-v3.0
    litellm_params:
      model: cohere/embed-multilingual-v3.0
      api_key: os.environ/COHERE_API_KEY
      input_type: search_document
  - model_name: embed-multilingual-light-v3.0
    litellm_params:
      model: cohere/embed-multilingual-light-v3.0
      api_key: os.environ/COHERE_API_KEY
      input_type: search_document
  
  # Embedding Models - Legacy Cohere v2
  - model_name: embed-english-v2.0
    litellm_params:
      model: cohere/embed-english-v2.0
      api_key: os.environ/COHERE_API_KEY
  - model_name: embed-english-light-v2.0
    litellm_params:
      model: cohere/embed-english-light-v2.0
      api_key: os.environ/COHERE_API_KEY
  - model_name: embed-multilingual-v2.0
    litellm_params:
      model: cohere/embed-multilingual-v2.0
      api_key: os.environ/COHERE_API_KEY
  
  # Embedding Models - Mistral
  - model_name: mistral-embed
    litellm_params:
      model: mistral/mistral-embed
      api_key: os.environ/MISTRAL_API_KEY
  
  # Embedding Models - Voyage
  - model_name: voyage-2
    litellm_params:
      model: voyage/voyage-2
      api_key: os.environ/VOYAGE_API_KEY

litellm_settings:
  drop_params: true
  set_verbose: false
  
  # Caching Configuration
  cache: true
  cache_params:
    type: redis
    host: os.environ/REDIS_HOST
    port: os.environ/REDIS_PORT
    password: os.environ/REDIS_PASSWORD
    ttl: 3600  # Cache for 1 hour
    namespace: "litellm_cache"
    
  # Success/Failure Callbacks (optional)
  # success_callback: ["langfuse", "webhook"]
  # failure_callback: ["langfuse", "webhook"]
  
  # Request Timeout
  request_timeout: 600
  
  # Retry Policy
  num_retries: 3
  retry_after: 5  # seconds

general_settings:
  # Master key for authentication
  master_key: os.environ/LITELLM_MASTER_KEY
  
  # Database Configuration
  database_url: os.environ/DATABASE_URL
  
  # Store model info in database
  store_model_in_db: true
  
  # UI Authentication
  ui_username: os.environ/UI_USERNAME
  ui_password: os.environ/UI_PASSWORD
  
  # Security
  custom_auth_header: "Authorization"
  max_parallel_requests: 100
  
  # User tracking for Open WebUI integration
  user_header_name: "X-OpenWebUI-User-Id"  # Options: X-OpenWebUI-User-Id, X-OpenWebUI-User-Email, X-OpenWebUI-User-Name
  
  # Logging
  json_logs: true
  
  # Health check endpoint
  health_check_interval: 60

router_settings:
  routing_strategy: "usage-based-routing-v2"
  
  # Model fallbacks
  model_group_alias: {
    "pixtral-large": ["pixtral-large", "mistral-large", "claude-opus-4", "gpt-4o", "gemini-2.5-pro", "command-a"],
    "mistral-large": ["mistral-large", "pixtral-large", "mistral-medium", "claude-opus-4", "gpt-4o", "gemini-2.5-pro", "command-a"],
    "mistral-medium": ["mistral-medium", "mistral-large", "mistral-small", "claude-3.5-sonnet", "gpt-4o", "gemini-2.5-flash", "command-r-plus"],
    "mistral-small": ["mistral-small", "mistral-saba", "ministral-8b", "claude-3.5-haiku", "gpt-4o-mini", "gemini-2.5-flash-lite", "command-r"],
    "magistral-medium": ["magistral-medium", "magistral-small", "o3", "sonar-reasoning-pro", "claude-opus-4", "grok-4"],
    "magistral-small": ["magistral-small", "magistral-medium", "o1", "sonar-reasoning", "claude-3.5-sonnet"],
    "codestral": ["codestral", "devstral-medium", "devstral-small", "gpt-4.1", "claude-sonnet-4"],
    "devstral-medium": ["devstral-medium", "codestral", "devstral-small", "gpt-4.1", "claude-3.5-sonnet"],
    "devstral-small": ["devstral-small", "codestral-mamba", "gpt-4.1-mini", "claude-3.5-haiku"],
    "command-a": ["command-a", "command-r-plus-08-2024", "command-r-plus", "claude-opus-4", "gpt-4o", "gemini-2.5-pro", "mistral-large"],
    "command-r-plus": ["command-r-plus-08-2024", "command-r-plus", "command-r", "claude-3.5-sonnet", "gpt-4o", "gemini-2.5-flash", "mistral-medium"],
    "command-r": ["command-r-08-2024", "command-r", "command-nightly", "claude-3.5-haiku", "gpt-4o-mini", "gemini-2.5-flash-lite", "mistral-small"],
    "sonar-reasoning-pro": ["sonar-reasoning-pro", "r1-1776", "sonar-reasoning", "o3", "claude-opus-4", "grok-4", "command-a", "magistral-medium"],
    "sonar-pro": ["sonar-pro", "sonar", "claude-3.5-sonnet", "gpt-4o", "gemini-2.5-flash", "command-r-plus", "mistral-medium"],
    "sonar-deep-research": ["sonar-deep-research", "sonar-reasoning-pro", "sonar-pro", "gpt-4o", "claude-opus-4", "command-a", "mistral-large"],
    "grok-4": ["grok-4", "grok-4-latest", "grok-3", "sonar-reasoning-pro", "claude-opus-4", "o3", "gpt-4o", "command-a", "mistral-large"],
    "grok-3": ["grok-3", "grok-beta", "sonar-pro", "claude-3.5-sonnet", "gpt-4o", "gemini-2.5-flash", "command-r-plus", "mistral-medium"],
    "grok-3-mini": ["grok-3-mini", "grok-beta", "sonar", "claude-3.5-haiku", "gpt-4o-mini", "gemini-2.5-flash-lite", "command-r", "mistral-small"],
    "gemini-2.5-pro": ["gemini-2.5-pro", "gemini-2.0-pro-exp", "gemini-1.5-pro", "sonar-reasoning-pro", "claude-opus-4", "grok-4", "gpt-4o", "command-a", "mistral-large"],
    "gemini-2.5-flash": ["gemini-2.5-flash", "gemini-2.0-flash", "gemini-1.5-flash", "sonar-pro", "claude-3.5-sonnet", "grok-3", "gpt-4o", "command-r-plus", "mistral-medium"],
    "gemini-2.5-flash-lite": ["gemini-2.5-flash-lite", "gemini-2.0-flash-lite", "gemini-1.5-flash", "sonar", "claude-3.5-haiku", "grok-3-mini", "gpt-4o-mini", "command-r", "mistral-small"],
    "claude-opus-4": ["claude-opus-4", "claude-3.5-sonnet", "claude-3-opus", "sonar-reasoning-pro", "grok-4", "gemini-2.5-pro", "gpt-4o", "command-a", "mistral-large"],
    "claude-sonnet-4": ["claude-sonnet-4", "claude-3.5-sonnet", "sonar-pro", "grok-3", "gemini-2.5-flash", "gpt-4o", "claude-3-sonnet", "command-r-plus", "mistral-medium"],
    "claude-3.5-sonnet": ["claude-3.5-sonnet", "claude-3-sonnet", "sonar-pro", "grok-3", "gpt-4o", "gemini-2.5-flash", "gemini-1.5-pro", "command-r-plus", "mistral-medium"],
    "claude-3.5-haiku": ["claude-3.5-haiku", "claude-3-haiku", "sonar", "grok-3-mini", "gpt-4o-mini", "gemini-2.5-flash-lite", "gemini-1.5-flash", "command-r", "mistral-small"],
    "gpt-4o": ["gpt-4o", "gpt-4.1", "sonar-pro", "grok-4", "claude-sonnet-4", "claude-3.5-sonnet", "gemini-2.5-flash", "gemini-1.5-pro", "command-r-plus", "mistral-large"],
    "gpt-4o-mini": ["gpt-4o-mini", "gpt-4.1-mini", "sonar", "grok-3-mini", "claude-3.5-haiku", "claude-3-haiku", "gemini-2.5-flash-lite", "gemini-1.5-flash", "command-r", "mistral-small"],
    "o3": ["o3", "o3-pro", "o1", "sonar-reasoning-pro", "r1-1776", "grok-4", "claude-opus-4", "gemini-2.5-pro", "gpt-4o", "command-a", "magistral-medium"],
    "o3-mini": ["o3-mini", "o1-mini", "sonar-reasoning", "grok-3-mini", "gpt-4o-mini", "claude-3.5-haiku", "gemini-2.5-flash-lite", "command-r", "magistral-small"],
    "r1-1776": ["r1-1776", "sonar-reasoning-pro", "o3", "grok-4", "claude-opus-4", "command-a", "magistral-medium"],
    "gpt-4": ["gpt-4", "gpt-4o", "claude-3-opus", "gemini-1.5-pro", "command-r-plus", "mistral-large"],
    "gpt-3.5-turbo": ["gpt-3.5-turbo", "gpt-4o-mini", "claude-3-haiku", "gemini-1.5-flash", "command-r", "mistral-small"],
  }
  
  # Redis settings for load balancing
  redis_host: os.environ/REDIS_HOST
  redis_port: os.environ/REDIS_PORT
  redis_password: os.environ/REDIS_PASSWORD
  
  # Cooldown settings
  cooldown_time: 30
  allowed_fails: 3
  
  # Enable fallbacks
  enable_fallbacks: true