version: '3.8'

services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    ports:
      - "3000:8080"
    environment:
      # Core Configuration
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}
      - WEBUI_NAME=${WEBUI_NAME}
      - WEBUI_URL=${WEBUI_URL}
      - DATABASE_URL=${DATABASE_URL}
      - ENV=${ENV}
      
      # LiteLLM Integration
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL}
      - OPENAI_API_BASE_URL=${OPENAI_API_BASE_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      
      # Security & Authentication
      - ENABLE_SIGNUP=${ENABLE_SIGNUP}
      - ENABLE_LOGIN_FORM=${ENABLE_LOGIN_FORM}
      - DEFAULT_USER_ROLE=${DEFAULT_USER_ROLE}
      - ENABLE_ADMIN_EXPORT=${ENABLE_ADMIN_EXPORT}
      - ENABLE_ADMIN_CHAT_ACCESS=${ENABLE_ADMIN_CHAT_ACCESS}
      
      # Features
      - ENABLE_RAG_WEB_SEARCH=${ENABLE_RAG_WEB_SEARCH}
      - ENABLE_WEB_SEARCH=${ENABLE_WEB_SEARCH}
      - ENABLE_IMAGE_GENERATION=${ENABLE_IMAGE_GENERATION}
      - ENABLE_CODE_EXECUTION=${ENABLE_CODE_EXECUTION}
      - ENABLE_CHANNELS=${ENABLE_CHANNELS}
      - ENABLE_COMMUNITY_SHARING=${ENABLE_COMMUNITY_SHARING}
      - ENABLE_MESSAGE_RATING=${ENABLE_MESSAGE_RATING}
      
      # RAG Configuration
      - RAG_EMBEDDING_ENGINE=${RAG_EMBEDDING_ENGINE}
      - RAG_RERANKING_MODEL=${RAG_RERANKING_MODEL}
      - RAG_EMBEDDING_MODEL=${RAG_EMBEDDING_MODEL}
      - ENABLE_RAG_LOCAL_WEB_FETCH=${ENABLE_RAG_LOCAL_WEB_FETCH}
      - ENABLE_RAG_WEB_LOADER_SSL_VERIFICATION=${ENABLE_RAG_WEB_LOADER_SSL_VERIFICATION}
      
      # Search Configuration
      - WEB_SEARCH_ENGINE=${WEB_SEARCH_ENGINE}
      - WEB_SEARCH_RESULT_COUNT=${WEB_SEARCH_RESULT_COUNT}
      - WEB_SEARCH_CONCURRENT_REQUESTS=${WEB_SEARCH_CONCURRENT_REQUESTS}
      
      # Performance
      - THREAD_POOL_SIZE=${THREAD_POOL_SIZE}
      - DATABASE_POOL_SIZE=${DATABASE_POOL_SIZE}
      - DATABASE_POOL_TIMEOUT=${DATABASE_POOL_TIMEOUT}
      
      # Logging
      - GLOBAL_LOG_LEVEL=${GLOBAL_LOG_LEVEL}
      
      # Redis (for multi-node deployments)
      - REDIS_URL=${REDIS_URL:-}
      - WEBSOCKET_REDIS_URL=${WEBSOCKET_REDIS_URL:-}
      - WEBSOCKET_MANAGER=${WEBSOCKET_MANAGER:-}
    volumes:
      - ./volumes/open-webui:/app/backend/data
      - ./config/open-webui:/app/backend/config
    depends_on:
      - postgres
      - litellm
    restart: unless-stopped

  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm
    ports:
      - "4000:4000"
    environment:
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/litellm
      # LLM Provider API Keys (add as needed)
      - OPENAI_API_KEY=${PROVIDER_OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${PROVIDER_ANTHROPIC_API_KEY:-}
      - GEMINI_API_KEY=${PROVIDER_GEMINI_API_KEY:-}
      - COHERE_API_KEY=${PROVIDER_COHERE_API_KEY:-}
      - MISTRAL_API_KEY=${PROVIDER_MISTRAL_API_KEY:-}
      - PERPLEXITY_API_KEY=${PROVIDER_PERPLEXITY_API_KEY:-}
      - GROQ_API_KEY=${PROVIDER_GROQ_API_KEY:-}
    volumes:
      - ./config/litellm/config.yaml:/app/config.yaml
    command: ["--config", "/app/config.yaml", "--port", "4000"]
    depends_on:
      - postgres
      - redis
    restart: unless-stopped

  postgres:
    image: postgres:15-alpine
    container_name: postgres
    environment:
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_USER=postgres
    volumes:
      - ./volumes/postgres:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: redis
    volumes:
      - ./volumes/redis:/data
    ports:
      - "6379:6379"
    restart: unless-stopped